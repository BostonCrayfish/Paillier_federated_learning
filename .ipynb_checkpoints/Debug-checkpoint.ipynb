{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chengbin/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "100%|██████████| 60000/60000 [00:00<00:00, 1825568.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from models.Trainer import *\n",
    "dataset='mnist'\n",
    "class_num=10\n",
    "\n",
    "net_glob,train_loder,test_loader=get_net_and_loader(dataset=dataset)\n",
    "\n",
    "traindata=train_loder.dataset.train_data\n",
    "targetdata=train_loder.dataset.targets\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def show(x,i):\n",
    "    #plt.figure(dpi=80)\n",
    "    #data=np.transpose(x.cpu().numpy(), (1,2,0))\n",
    "    data=x.cpu().numpy()\n",
    "    # plt.imshow(data,cmap='gray') \n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    im = Image.fromarray(data)\n",
    "    im.save(i)\n",
    "    \n",
    "dir_name='data/{}/train'.format(dataset)\n",
    "    \n",
    "for i in range(class_num):\n",
    "    child_dir_name='{}/{}/'.format(dir_name,i)\n",
    "    if not os.path.isdir(child_dir_name):\n",
    "        mkdir_p(child_dir_name)\n",
    "    \n",
    "for i in tqdm(range(len(traindata))):\n",
    "    #show(traindata[i],'{}/{}/{}_{}.jpg'.format(dir_name,targetdata[i],targetdata[i],i))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.sampling import *\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, traindata,targetdata, idxs):\n",
    "        self.traindata = traindata\n",
    "        self.targetdata= targetdata\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        print(self.idxs[item])\n",
    "        image, label = self.traindata[self.idxs[item]],self.targetdata[self.idxs[item]]\n",
    "        return image, label\n",
    "    \n",
    "def save(dataset,dir_name):\n",
    "    traindata = dataset.traindata\n",
    "    targetdata= dataset.targetdata\n",
    "    if not os.path.isdir(dir_name):\n",
    "        mkdir_p(dir_name)\n",
    "    \n",
    "    for i in range(class_num):\n",
    "        child_dir_name='{}/{}/'.format(dir_name,i)\n",
    "        if not os.path.isdir(child_dir_name):\n",
    "            mkdir_p(child_dir_name)\n",
    "    \n",
    "    for i in tqdm(range(len(traindata))):\n",
    "        data=traindata[i].cpu().numpy()\n",
    "        im = Image.fromarray(data)\n",
    "        im.save(i)\n",
    "        show(traindata[i],'{}/{}/{}_{}.jpg'.format(dir_name,targetdata[i],targetdata[i],i))\n",
    "\n",
    "dict_users = mnist_iid(traindata, 4)\n",
    "\n",
    "for idx in dict_users:\n",
    "    x=DatasetSplit(traindata,targetdata, dict_users[idx])\n",
    "    dir_name='test_data/{}/train/part_{}'.format(dataset,idx)\n",
    "    save(x,dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "sock=socket.socket()\n",
    "sock.connect((\"localhost\",22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import pickle\n",
    "w=net_glob.cpu().state_dict()\n",
    "w=dict(w)\n",
    "\n",
    "#data = dict({key:value.numpy() for key,value in w.items()})\n",
    "print(w)\n",
    "w1=pickle.dumps(w)\n",
    "print(w1)\n",
    "w2=pickle.loads(w1) \n",
    "print(w2)\n",
    "net_glob.load_state_dict(w2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chengbin/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
